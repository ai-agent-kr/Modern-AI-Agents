{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKSW07erA50E",
        "outputId": "9fa99aec-1147-49f9-da8b-9bd742ecc3b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-learn sentence-transformers transformers torch numpy accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile travel_planning_qwen25.py\n",
        "\n",
        "\"\"\"\n",
        "Travel Planning System with Multi-Agent Architecture\n",
        "\n",
        "This script defines multiple specialized agents, each designed for a specific aspect of travel planning:\n",
        "\n",
        "1. WeatherAnalysisAgent:\n",
        "   - Predicts the best months to visit a location using historical weather data.\n",
        "   - Uses a Random Forest regression model for predictions.\n",
        "\n",
        "2. HotelRecommenderAgent:\n",
        "   - Recommends hotels based on semantic similarity between user preferences and hotel descriptions.\n",
        "   - Utilizes SentenceTransformer embeddings for semantic comparison.\n",
        "\n",
        "3. ItineraryPlannerAgent:\n",
        "   - Generates detailed travel itineraries using a text-generation language model.\n",
        "   - Leverages the Qwen2.5-3B-Instruct model for generating realistic itineraries based on provided prompts.\n",
        "\n",
        "4. SummaryAgent:\n",
        "   - Summarizes the travel plan details into a concise, client-friendly email.\n",
        "   - Estimates the total cost of the trip and uses Qwen2.5-3B-Instruct to generate the summary content.\n",
        "\n",
        "These agents collectively enable an automated and intelligent approach to personalized travel planning.\n",
        "\"\"\"\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "class WeatherAnalysisAgent:\n",
        "    \"\"\"\n",
        "    An agent that analyzes historical weather data to predict optimal travel periods.\n",
        "\n",
        "    Attributes:\n",
        "        model (RandomForestRegressor): A random forest model trained on historical weather data.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Uses RandomForest for weather predictions based on historical data\n",
        "        self.model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "    def train(self, historical_data: Dict):\n",
        "        # Training on historical weather data\n",
        "        X = np.array([[d['month'], d['latitude'], d['longitude']] for d in historical_data])\n",
        "        y = np.array([d['weather_score'] for d in historical_data])\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def predict_best_time(self, location: Dict) -> Dict:\n",
        "        # Predicts the best time to visit a location based on weather patterns\n",
        "        predictions = []\n",
        "        for month in range(1, 13):\n",
        "            # predict returns a 2D array, we take the first (and only) element\n",
        "            prediction = self.model.predict([[\n",
        "                month,\n",
        "                location['latitude'],\n",
        "                location['longitude']\n",
        "            ]]).item()  # .item() converts numpy array to scalar\n",
        "            predictions.append({'month': month, 'score': float(prediction)})\n",
        "\n",
        "        return {\n",
        "            'best_months': sorted(predictions, key=lambda x: x['score'], reverse=True)[:3],\n",
        "            'location': location\n",
        "        }\n",
        "\n",
        "\n",
        "class HotelRecommenderAgent:\n",
        "    \"\"\"\n",
        "    An agent for recommending hotels that best match user preferences using semantic embeddings.\n",
        "\n",
        "    Attributes:\n",
        "        encoder (SentenceTransformer): Sentence embedding model for semantic matching.\n",
        "        hotels_db (List[Dict]): Database of hotel information.\n",
        "        hotels_embeddings (np.ndarray): Precomputed embeddings of hotel descriptions.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # Uses SentenceTransformer for hotel description embeddings\n",
        "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.hotels_db = []\n",
        "        self.hotels_embeddings = None\n",
        "\n",
        "    def add_hotels(self, hotels: List[Dict]):\n",
        "        # Updates the hotel database and computes embeddings\n",
        "        self.hotels_db = hotels\n",
        "        descriptions = [h['description'] for h in hotels]\n",
        "        self.hotels_embeddings = self.encoder.encode(descriptions)\n",
        "\n",
        "    def find_hotels(self, preferences: str, top_k: int = 5) -> List[Dict]:\n",
        "        # Finds hotels most similar to preferences using semantic similarity\n",
        "        pref_embedding = self.encoder.encode([preferences])\n",
        "        similarities = np.dot(self.hotels_embeddings, pref_embedding.T).flatten()\n",
        "\n",
        "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "        return [\n",
        "            {**self.hotels_db[i], 'similarity_score': float(similarities[i])}\n",
        "            for i in top_indices\n",
        "        ]\n",
        "\n",
        "\n",
        "class ItineraryPlannerAgent:\n",
        "    \"\"\"\n",
        "    An agent that creates travel itineraries by generating descriptive text using Qwen2.5-3B.\n",
        "\n",
        "    Attributes:\n",
        "        tokenizer: Qwen2.5 tokenizer\n",
        "        model: Qwen2.5-3B-Instruct model with 4-bit quantization\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        print(\"Qwen2.5-3B \ubaa8\ub378 \ub85c\ub529 \uc911...\")\n",
        "\n",
        "        # 4-bit quantization config for T4 GPU memory optimization\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "\n",
        "        model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        print(\"\ubaa8\ub378 \ub85c\ub529 \uc644\ub8cc!\")\n",
        "\n",
        "    def create_itinerary(self, destination_info: Dict, weather_info: Dict,\n",
        "                         hotel_info: Dict, duration: int) -> Dict:\n",
        "        prompt = self._create_prompt(destination_info, weather_info, hotel_info, duration)\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"\ub2f9\uc2e0\uc740 \uc804\ubb38 \uc5ec\ud589 \ud50c\ub798\ub108\uc785\ub2c8\ub2e4. \uad6c\uccb4\uc801\uc774\uace0 \uc2e4\uc6a9\uc801\uc778 \uc5ec\ud589 \uc77c\uc815\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        # Generate the itinerary\n",
        "        generated_ids = self.model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=400,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return {\n",
        "            'itinerary': response,\n",
        "            'duration': duration,\n",
        "            'destination': destination_info['name']\n",
        "        }\n",
        "\n",
        "    def _create_prompt(self, destination_info: Dict, weather_info: Dict,\n",
        "                       hotel_info: Dict, duration: int) -> str:\n",
        "        return f\"\"\"\ub2e4\uc74c \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c {duration}\uc77c\uac04\uc758 \uc0c1\uc138\ud55c \uc5ec\ud589 \uc77c\uc815\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694:\n",
        "\n",
        "\ubaa9\uc801\uc9c0: {destination_info['name']}\n",
        "\ucd5c\uc801 \ubc29\ubb38 \uc2dc\uae30: {weather_info['best_months'][0]['month']}\uc6d4\n",
        "\uc219\ubc15: {hotel_info[0]['name']}\n",
        "\uc8fc\uc694 \uad00\uad11\uc9c0: {', '.join(destination_info['attractions'])}\n",
        "\n",
        "\uac01 \ub0a0\uc9dc\ubcc4\ub85c \uc544\uce68, \uc810\uc2ec, \uc800\ub141 \uc77c\uc815\uc744 \ud3ec\ud568\ud558\uc5ec \uad6c\uccb4\uc801\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694.\"\"\"\n",
        "\n",
        "\n",
        "class SummaryAgent:\n",
        "    \"\"\"\n",
        "    An agent that generates summarized travel plans in the form of personalized emails.\n",
        "\n",
        "    Attributes:\n",
        "        tokenizer: Qwen2.5 tokenizer\n",
        "        model: Qwen2.5-3B-Instruct model with 4-bit quantization for email creation\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        print(\"Qwen2.5-3B \ubaa8\ub378 \ub85c\ub529 \uc911... (SummaryAgent)\")\n",
        "\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "\n",
        "        model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        print(\"\ubaa8\ub378 \ub85c\ub529 \uc644\ub8cc!\")\n",
        "\n",
        "    def calculate_total_price(self, hotel_info: Dict, duration: int) -> float:\n",
        "        # Calculate total trip price\n",
        "        hotel_cost = hotel_info[0]['price'] * duration\n",
        "        # Estimate additional costs (activities, meals, transport)\n",
        "        daily_expenses = 100  # Simplified example\n",
        "        additional_costs = daily_expenses * duration\n",
        "\n",
        "        return hotel_cost + additional_costs\n",
        "\n",
        "    def create_email(self, trip_data: Dict, client_name: str) -> Dict:\n",
        "        total_price = self.calculate_total_price(\n",
        "            trip_data['recommended_hotels'],\n",
        "            trip_data['itinerary']['duration']\n",
        "        )\n",
        "\n",
        "        prompt = f\"\"\"\ub2e4\uc74c \uc5ec\ud589 \uacc4\ud68d \uc815\ubcf4\ub97c \ubc14\ud0d5\uc73c\ub85c \uace0\uac1d\uc5d0\uac8c \ubcf4\ub0bc \uc804\ubb38\uc801\uc778 \uc774\uba54\uc77c\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694:\n",
        "\n",
        "\uace0\uac1d\uba85: {client_name}\n",
        "\ubaa9\uc801\uc9c0: {trip_data['itinerary']['destination']}\n",
        "\uae30\uac04: {trip_data['itinerary']['duration']}\uc77c\n",
        "\ucd5c\uc801 \ubc29\ubb38 \uc2dc\uae30: {trip_data['weather_analysis']['best_months'][0]['month']}\uc6d4\n",
        "\ucd94\ucc9c \ud638\ud154: {trip_data['recommended_hotels'][0]['name']}\n",
        "\uc608\uc0c1 \ucd1d \ube44\uc6a9: ${total_price}\n",
        "\n",
        "\uc5ec\ud589 \uc77c\uc815:\n",
        "{trip_data['itinerary']['itinerary']}\n",
        "\n",
        "\uc815\uc911\ud558\uace0 \uc804\ubb38\uc801\uc778 \ud1a4\uc73c\ub85c \uc791\uc131\ud574\uc8fc\uc138\uc694.\"\"\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"\ub2f9\uc2e0\uc740 \uc804\ubb38 \uc5ec\ud589\uc0ac \uc9c1\uc6d0\uc785\ub2c8\ub2e4. \uace0\uac1d\uc5d0\uac8c \ubcf4\ub0bc \uc815\uc911\ud558\uace0 \uc0c1\uc138\ud55c \uc774\uba54\uc77c\uc744 \uc791\uc131\ud574\uc8fc\uc138\uc694.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        # Generate email using LLM\n",
        "        generated_ids = self.model.generate(\n",
        "            **model_inputs,\n",
        "            max_new_tokens=600,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return {\n",
        "            'email_content': response,\n",
        "            'total_price': total_price,\n",
        "            'summary_data': {\n",
        "                'destination': trip_data['itinerary']['destination'],\n",
        "                'duration': trip_data['itinerary']['duration'],\n",
        "                'hotel': trip_data['recommended_hotels'][0]['name'],\n",
        "                'best_month': trip_data['weather_analysis']['best_months'][0]['month']\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "class TravelPlanningSystem:\n",
        "    def __init__(self):\n",
        "        self.weather_agent = WeatherAnalysisAgent()\n",
        "        self.hotel_agent = HotelRecommenderAgent()\n",
        "        self.itinerary_agent = ItineraryPlannerAgent()\n",
        "        self.summary_agent = SummaryAgent()\n",
        "\n",
        "    def setup(self, historical_weather_data: Dict, hotels_database: List[Dict]):\n",
        "        # Initialize and train the models\n",
        "        self.weather_agent.train(historical_weather_data)\n",
        "        self.hotel_agent.add_hotels(hotels_database)\n",
        "\n",
        "    def plan_trip(self, destination: Dict, preferences: str, duration: int, client_name: str) -> Dict:\n",
        "        # 1. Weather analysis and best time prediction\n",
        "        weather_analysis = self.weather_agent.predict_best_time(destination)\n",
        "\n",
        "        # 2. Hotel search\n",
        "        recommended_hotels = self.hotel_agent.find_hotels(preferences)\n",
        "\n",
        "        # 3. Itinerary creation\n",
        "        itinerary = self.itinerary_agent.create_itinerary(\n",
        "            destination,\n",
        "            weather_analysis,\n",
        "            recommended_hotels,\n",
        "            duration\n",
        "        )\n",
        "\n",
        "        # 4. Create summary email and calculate price\n",
        "        trip_data = {\n",
        "            'weather_analysis': weather_analysis,\n",
        "            'recommended_hotels': recommended_hotels,\n",
        "            'itinerary': itinerary\n",
        "        }\n",
        "\n",
        "        summary = self.summary_agent.create_email(trip_data, client_name)\n",
        "\n",
        "        return {\n",
        "            **trip_data,\n",
        "            'summary': summary\n",
        "        }\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Example data with a full year of weather information\n",
        "    historical_weather_data = [\n",
        "        {'month': 1, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.5},\n",
        "        {'month': 2, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.6},\n",
        "        {'month': 3, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.7},\n",
        "        {'month': 4, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.8},\n",
        "        {'month': 5, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.85},\n",
        "        {'month': 6, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.9},\n",
        "        {'month': 7, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.95},\n",
        "        {'month': 8, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.9},\n",
        "        {'month': 9, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.85},\n",
        "        {'month': 10, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.7},\n",
        "        {'month': 11, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.6},\n",
        "        {'month': 12, 'latitude': 41.9028, 'longitude': 12.4964, 'weather_score': 0.5},\n",
        "    ]\n",
        "\n",
        "    # Sample hotel database\n",
        "    hotels_database = [\n",
        "        {\n",
        "            'name': 'Grand Hotel',\n",
        "            'description': 'Luxury hotel in city center with spa and restaurant',\n",
        "            'price': 300\n",
        "        },\n",
        "        {\n",
        "            'name': 'Boutique Resort',\n",
        "            'description': 'Intimate boutique hotel with personalized service',\n",
        "            'price': 250\n",
        "        },\n",
        "        {\n",
        "            'name': 'City View Hotel',\n",
        "            'description': 'Modern hotel with panoramic city views',\n",
        "            'price': 200\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Initialize the system\n",
        "    system = TravelPlanningSystem()\n",
        "    system.setup(historical_weather_data, hotels_database)\n",
        "\n",
        "    # Plan a trip\n",
        "    destination = {\n",
        "        'name': 'Rome',\n",
        "        'latitude': 41.9028,\n",
        "        'longitude': 12.4964,\n",
        "        'attractions': ['Colosseum', 'Vatican', 'Trevi Fountain']\n",
        "    }\n",
        "\n",
        "    preferences = \"\"\"Looking for a luxury hotel in the city center,\n",
        "    preferably with spa facilities and fine dining options\"\"\"\n",
        "\n",
        "    client_name = \"John Smith\"\n",
        "\n",
        "    # Generate trip plan\n",
        "    trip_plan = system.plan_trip(destination, preferences, duration=3, client_name=client_name)\n",
        "\n",
        "    # Print results in a readable format\n",
        "    print(\"\\nTRAVEL PLANNING RESULTS:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Client: {client_name}\")\n",
        "    print(f\"Destination: {destination['name']}\")\n",
        "    print(\"\\nGenerated Email:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(trip_plan['summary']['email_content'])\n",
        "    print(\"\\nEstimated Total Price:\")\n",
        "    print(f\"${trip_plan['summary']['total_price']}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3nXLARsBAFn",
        "outputId": "7ee565d4-df53-4cf1-8041-fb16e61d6223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing travel_planning_qwen25.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAAypwQOBHux",
        "outputId": "b040b5d5-d6af-4537-9ba4-8d4039de4f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 32\n",
            "drwxr-xr-x 1 root root  4096 Oct 12 15:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root  4096 Oct 12 15:20 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root  4096 Oct  9 13:35 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root  4096 Oct  9 13:36 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 14762 Oct 12 15:22 travel_planning_qwen25.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python travel_planning_qwen25.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUQuOE4rBF8H",
        "outputId": "f4a3079b-bf8e-4706-ff79-9f7264ceded8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-12 15:23:39.163411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760282619.195550     968 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760282619.205533     968 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760282619.230719     968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760282619.230757     968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760282619.230765     968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760282619.230773     968 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-12 15:23:39.237729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "modules.json: 100% 349/349 [00:00<00:00, 3.15MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 1.12MB/s]\n",
            "README.md: 10.5kB [00:00, 46.6MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 614kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 6.48MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:00<00:00, 93.4MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 3.67MB/s]\n",
            "vocab.txt: 232kB [00:00, 21.9MB/s]\n",
            "tokenizer.json: 466kB [00:00, 49.6MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 971kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 2.13MB/s]\n",
            "Qwen2.5-3B \ubaa8\ub378 \ub85c\ub529 \uc911...\n",
            "tokenizer_config.json: 7.30kB [00:00, 37.2MB/s]\n",
            "vocab.json: 2.78MB [00:00, 134MB/s]\n",
            "merges.txt: 1.67MB [00:00, 131MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 178MB/s]\n",
            "config.json: 100% 661/661 [00:00<00:00, 6.93MB/s]\n",
            "model.safetensors.index.json: 35.6kB [00:00, 113MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.20G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 843k/2.20G [00:01<47:37, 771kB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 15.3M/2.20G [00:01<02:37, 13.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 20.3k/3.97G [00:01<91:35:28, 12.0kB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.9M/2.20G [00:01<02:33, 14.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 47.6M/2.20G [00:02<01:09, 30.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 9.40M/3.97G [00:02<12:35, 5.24MB/s]   \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 59.4M/2.20G [00:02<01:23, 25.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 10.4M/3.97G [00:03<17:16, 3.82MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 75.1M/2.20G [00:03<01:09, 30.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 120M/2.20G [00:03<00:35, 59.4MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 132M/2.20G [00:03<00:31, 65.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 151M/2.20G [00:03<00:25, 79.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 18.7M/3.97G [00:03<10:14, 6.42MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 163M/2.20G [00:04<00:43, 46.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 19.7M/3.97G [00:04<13:22, 4.92MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 177M/2.20G [00:04<00:36, 56.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 26.1M/3.97G [00:04<07:55, 8.29MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 37.1M/3.97G [00:04<04:23, 14.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 198M/2.20G [00:06<01:45, 18.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 62.2M/3.97G [00:07<05:49, 11.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 227M/2.20G [00:07<01:17, 25.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 96.1M/3.97G [00:07<03:00, 21.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 104M/3.97G [00:08<03:13, 19.9MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 237M/2.20G [00:08<01:35, 20.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 245M/2.20G [00:08<01:31, 21.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 275M/2.20G [00:08<00:54, 35.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 131M/3.97G [00:09<03:07, 20.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 284M/2.20G [00:13<03:11, 10.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 326M/2.20G [00:13<01:33, 20.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 375M/2.20G [00:13<00:54, 33.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 393M/2.20G [00:13<00:50, 36.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 453M/2.20G [00:14<00:36, 47.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 157M/3.97G [00:14<06:50, 9.28MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 176M/3.97G [00:17<06:57, 9.08MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 509M/2.20G [00:17<00:49, 34.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 178M/3.97G [00:17<06:53, 9.17MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 528M/2.20G [00:17<00:51, 32.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 595M/2.20G [00:18<00:30, 52.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 636M/2.20G [00:18<00:26, 59.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 242M/3.97G [00:19<03:28, 17.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 658M/2.20G [00:23<01:19, 19.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 252M/3.97G [00:23<06:18, 9.82MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 725M/2.20G [00:23<00:47, 31.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 769M/2.20G [00:27<01:06, 21.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 319M/3.97G [00:27<04:54, 12.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 345M/3.97G [00:27<03:49, 15.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 790M/2.20G [00:30<01:33, 15.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 381M/3.97G [00:31<04:37, 12.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 796M/2.20G [00:31<01:38, 14.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 447M/3.97G [00:31<02:36, 22.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 465M/3.97G [00:32<02:31, 23.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 864M/2.20G [00:33<01:01, 21.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 532M/3.97G [00:33<01:41, 34.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 908M/2.20G [00:33<00:42, 30.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 541M/3.97G [00:33<01:36, 35.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 945M/2.20G [00:34<00:37, 33.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 571M/3.97G [00:34<01:48, 31.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 662M/3.97G [00:35<01:06, 50.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.01G/2.20G [00:35<00:31, 38.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.04G/2.20G [00:35<00:26, 43.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 671M/3.97G [00:35<01:07, 48.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 738M/3.97G [00:36<00:52, 62.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 789M/3.97G [00:36<00:43, 73.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 798M/3.97G [00:37<00:43, 72.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 809M/3.97G [00:37<00:49, 64.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.05G/2.20G [00:37<00:43, 26.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 819M/3.97G [00:37<00:54, 57.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 831M/3.97G [00:37<00:52, 59.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 843M/3.97G [00:38<00:50, 61.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 862M/3.97G [00:39<01:56, 26.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 906M/3.97G [00:40<01:10, 43.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.10G/2.20G [00:40<00:46, 23.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 916M/3.97G [00:40<01:15, 40.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 931M/3.97G [00:40<01:22, 36.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.15G/2.20G [00:41<00:34, 30.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 993M/3.97G [00:49<04:45, 10.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.07G/3.97G [00:50<02:20, 20.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.09G/3.97G [00:50<02:04, 23.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.22G/2.20G [00:56<01:47, 9.16MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.10G/3.97G [00:56<04:36, 10.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.17G/3.97G [00:56<02:20, 19.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.25G/3.97G [01:00<02:19, 19.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.29G/2.20G [01:00<01:25, 10.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.31G/3.97G [01:06<02:59, 14.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 1.36G/2.20G [01:08<01:27, 9.70MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.34G/3.97G [01:10<03:19, 13.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.35G/3.97G [01:10<03:10, 13.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 1.42G/2.20G [01:16<01:24, 9.22MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 1.48G/2.20G [01:16<00:55, 13.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.42G/3.97G [01:17<03:37, 11.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.55G/2.20G [01:20<00:45, 14.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.43G/3.97G [01:21<04:49, 8.79MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.43G/3.97G [01:21<04:37, 9.15MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.62G/2.20G [01:21<00:29, 19.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.44G/3.97G [01:21<04:13, 9.99MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.46G/3.97G [01:22<03:00, 13.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.47G/3.97G [01:22<02:41, 15.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 1.69G/2.20G [01:22<00:20, 25.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.48G/3.97G [01:22<02:25, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.49G/3.97G [01:23<02:50, 14.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.50G/3.97G [01:24<03:36, 11.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.76G/2.20G [01:24<00:17, 26.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.51G/3.97G [01:25<03:02, 13.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 1.80G/2.20G [01:25<00:14, 27.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.57G/3.97G [01:26<01:29, 26.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 1.64G/3.97G [01:26<00:44, 51.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 1.84G/2.20G [01:27<00:12, 29.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 1.69G/3.97G [01:30<01:34, 24.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 1.89G/2.20G [01:30<00:15, 20.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 1.77G/3.97G [01:34<01:42, 21.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 1.85G/3.97G [01:41<02:02, 17.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.94G/2.20G [01:41<00:25, 10.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 1.86G/3.97G [01:41<01:57, 18.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 1.87G/3.97G [01:41<01:50, 19.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 1.88G/3.97G [01:41<01:43, 20.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 1.95G/3.97G [01:45<01:47, 18.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.01G/3.97G [01:46<01:07, 29.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.02G/3.97G [01:46<01:05, 29.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.04G/3.97G [01:46<00:56, 34.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 2.00G/2.20G [01:46<00:18, 11.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.05G/3.97G [01:46<00:54, 35.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.08G/3.97G [01:46<00:37, 50.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.11G/3.97G [01:47<00:31, 59.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.12G/3.97G [01:47<00:30, 60.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.13G/3.97G [01:48<00:49, 36.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.16G/3.97G [01:51<01:46, 16.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.19G/3.97G [01:55<02:38, 11.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 2.07G/2.20G [01:55<00:14, 9.56MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.23G/3.97G [01:55<01:37, 17.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.30G/3.97G [01:56<00:55, 30.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.14G/2.20G [01:57<00:05, 12.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.36G/3.97G [01:57<00:40, 39.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 2.43G/3.97G [02:00<00:48, 32.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 2.50G/3.97G [02:00<00:34, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 2.56G/3.97G [02:01<00:24, 57.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 2.62G/3.97G [02:01<00:20, 64.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 2.67G/3.97G [02:05<00:41, 31.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 2.75G/3.97G [02:05<00:25, 47.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 2.85G/3.97G [02:06<00:17, 65.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 2.90G/3.97G [02:07<00:16, 63.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.14G/2.20G [02:08<00:05, 12.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.20G/2.20G [02:12<00:00, 8.04MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 2.20G/2.20G [02:12<00:00, 16.7MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.04G/3.97G [02:15<00:38, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.07G/3.97G [02:16<00:31, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.13G/3.97G [02:20<00:37, 22.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 3.20G/3.97G [02:20<00:25, 30.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 3.27G/3.97G [02:21<00:17, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 3.33G/3.97G [02:21<00:11, 53.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 3.38G/3.97G [02:22<00:08, 65.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 3.44G/3.97G [02:22<00:07, 74.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 3.51G/3.97G [02:23<00:05, 81.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 3.57G/3.97G [02:23<00:04, 93.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 3.63G/3.97G [02:24<00:03, 111MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 3.70G/3.97G [02:24<00:02, 103MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 3.77G/3.97G [02:25<00:01, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 3.83G/3.97G [02:25<00:01, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 3.90G/3.97G [02:26<00:00, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 3.97G/3.97G [02:26<00:00, 27.1MB/s]\n",
            "Fetching 2 files: 100% 2/2 [02:26<00:00, 73.44s/it] \n",
            "Loading checkpoint shards: 100% 2/2 [00:29<00:00, 14.57s/it]\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 2.29MB/s]\n",
            "\ubaa8\ub378 \ub85c\ub529 \uc644\ub8cc!\n",
            "Qwen2.5-3B \ubaa8\ub378 \ub85c\ub529 \uc911... (SummaryAgent)\n",
            "Loading checkpoint shards: 100% 2/2 [00:26<00:00, 13.46s/it]\n",
            "\ubaa8\ub378 \ub85c\ub529 \uc644\ub8cc!\n",
            "\n",
            "TRAVEL PLANNING RESULTS:\n",
            "--------------------------------------------------\n",
            "Client: John Smith\n",
            "Destination: Rome\n",
            "\n",
            "Generated Email:\n",
            "--------------------\n",
            "\uc548\ub155\ud558\uc138\uc694, \uc874 \uc18c\ubbf8\uc5b4 \ub2d8,\n",
            "\n",
            "7\uc6d4\uc5d0 Rome\ub97c \ubc29\ubb38\ud558\uc2dc\ub824\ub294 \uacc4\ud68d\uc5d0 \ub300\ud574 \ub9e4\uc6b0 \uae30\uc069\ub2c8\ub2e4. \uc81c \uc5ec\ud589\uc0ac\uac00 \uc81c\uacf5\ud558\ub294 \ucd94\ucc9c \uc77c\uc815\uacfc \ube44\uc6a9 \ub4f1\uc744 \ud3ec\ud568\ud558\uc5ec, \uba87 \uac00\uc9c0 \uc870\uc5b8\uacfc \ud568\uaed8 \uc774\uba54\uc77c\uc744 \ubcf4\ub0b4\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.\n",
            "\n",
            "1\uc77c \uc77c\uc815:\n",
            "- \uc624\uc804 8:00 - 9:00: Grand Hotel\uc5d0\uc11c \uac04\ub2e8\ud55c \uc544\uce68 \uc2dd\uc0ac\ub97c \uc990\uaca8\ubcf4\uc138\uc694.\n",
            "- \uc624\uc804 9:00 - 10:30: Colosseum\uc5d0 \uac00\uc11c \ub85c\ub9c8 \uc5ed\uc0ac\ub97c \uccb4\ud5d8\ud558\uba70 Roman Empire\uc758 \uaddc\ubaa8\ub97c \uc0b4\ud3b4\ubcf4\uc138\uc694.\n",
            "- \uc624\ud6c4 10:30 - 12:30: Vatican City\ub97c \ubc29\ubb38\ud558\uace0 \uc131\ubaa8 \ub9c8\ub9ac\uc544\uc640 \uc608\uc218\ub97c \uc704\ud55c \uc0ac\uc6d0\ub4e4\uc744 \uad00\ub78c\ud569\ub2c8\ub2e4. \ub610\ud55c, \uad50\ud669\uccad\ub3c4 \ubc29\ubb38\ud558\uba74\uc11c \uad50\ud68c\uc758 \uc815\uc218\ub97c \uccb4\ud5d8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
            "- \uc624\ud6c4 12:30 - 13:30: Vatican \uadfc\ucc98\uc758 \ub808\uc2a4\ud1a0\ub791\uc5d0\uc11c \uc720\ub7fd \uc694\ub9ac\ub97c \ub9db\ubcf4\uc138\uc694.\n",
            "- \uc624\ud6c4 13:30 - 15:30: Trevi Fountain\uc744 \ubc29\ubb38\ud558\uace0, Via Veneto\ub97c \uc0b0\ucc45\ud558\uba70 \ubb3c\uc744 \ud22d\ud22d \uc3df\uc544\ub0b4\ub294 \ud589\uc6b4\uc744 \uc5bb\uc73c\uc138\uc694.\n",
            "- \uc624\ud6c4 15:30 - 16:30: Vatican City\ub97c \ud1f4\uc2e4\ud569\ub2c8\ub2e4.\n",
            "\n",
            "\uc774 \uc77c\uc815\uc740 \ub85c\ub9c8\uc758 \uc5ed\uc0ac\uc640 \ubb38\ud654\ub97c \uccb4\ud5d8\ud558\uba70, \uadf8 \uc9c0\uc5ed\uc758 \ud2b9\ubcc4\ud55c \uacbd\ud5d8\uc744 \ub9cc\ub07d\ud558\uc2e4 \uc218 \uc788\ub3c4\ub85d \uad6c\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc608\uc0c1 \ucd1d \ube44\uc6a9\uc740 $1200\uc785\ub2c8\ub2e4.\n",
            "\n",
            "\uc704\uc758 \uc77c\uc815\uc5d0 \ub300\ud55c \ucd94\uac00\uc801\uc778 \uc9c8\ubb38\uc774\ub098 \uc548\ub0b4\uac00 \ud544\uc694\ud558\uc2dc\ub2e4\uba74 \uc5b8\uc81c\ub4e0\uc9c0 \uc54c\ub824\uc8fc\uc2dc\uba74 \uac10\uc0ac\ud558\uaca0\uc2b5\ub2c8\ub2e4. Rome\uc758 \uc544\ub984\ub2e4\uc6b4 \ub3c4\uc2dc\uc640 \ud48d\uacbd, \uadf8\ub9ac\uace0 \ub85c\ub9c8 \uc5ed\uc0ac\uc758 \ub9e4\ub825\uc801\uc778 \uc7a5\uc18c\ub4e4\uc744 \uccb4\ud5d8\ud560 \uc218 \uc788\ub294 \uc774 \uae30\ud68c\ub97c \ub193\uce58\uc9c0 \uc54a\ub3c4\ub85d \ub3c4\uc640\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.\n",
            "\n",
            "Rome \uc5ec\ud589\uc774 \uae30\ub300\ub418\ub294 \uac83\ucc98\ub7fc, \uc88b\uc740 \ud558\ub8e8 \ub418\uc138\uc694!\n",
            "\n",
            "\uac10\uc0ac\ud569\ub2c8\ub2e4,\n",
            "[Your Name]\n",
            "[Your Company]\n",
            "\n",
            "Estimated Total Price:\n",
            "$1200\n"
          ]
        }
      ]
    }
  ]
}